# .github/workflows/update-deals.yml

permissions:
  contents: write       # allow the GITHUB_TOKEN to push commits

name: update-deals

on:
  schedule:
    - cron: '0 * * * *'     # runs at the top of every hour
  workflow_dispatch:        # allows manual runs from the Actions UI

jobs:
  fetch-deals:
    runs-on: ubuntu-latest

    steps:
      # 1️⃣ Checkout your code, preserving the GITHUB_TOKEN credentials
      - name: Checkout repo
        uses: actions/checkout@v3
        with:
          persist-credentials: true

      # 2️⃣ Install Node.js so we can run our scraper
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '16'

      # 3️⃣ Install any npm dependencies (axios, cheerio, etc.)
      - name: Install dependencies
        run: npm install

      # 4️⃣ Run your scraper, passing in any AWS or partner secrets
      - name: Fetch new deals
        env:
          AWS_ACCESS_KEY_ID:     ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          PARTNER_TAG:           ${{ secrets.PARTNER_TAG }}
        run: node deals.js

      # 5️⃣ Commit & push the updated deals.json back to the repo
      - name: Commit & push updated deals.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add deals.json
          git commit -m "chore: update deals"
          git push
